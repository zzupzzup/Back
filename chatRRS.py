# -*- coding: utf-8 -*-
"""ChatRRS_0510.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1eI25Vj7Ntb__7KeoQ7yTMBqKNfjVw-ZJ
"""


from sentence_transformers import SentenceTransformer, util
import pandas as pd
import time
from tqdm import tqdm
import numpy as np
import pickle
import faiss
import json

import torch
from fastapi import APIRouter, Depends
from models import ChatRRS_Detail_Item
from sqlalchemy import create_engine, text
from app.common.config import LocalConfig
from sqlalchemy.orm import Session
from app.database.conn import db
from app.database.schema import Stores, Reviews
from models import ChatRRS_Detail_Item
import json
from sqlalchemy.sql import text

from os import path
from connectS3 import upload_to_aws, download_from_aws


# 이 파일의 데이터인 review_0510_1655.csv, encoded_data_0510_1925.npy 는 s3 에 저장되기 때문에 
# response_model 을 쓸 수가 없다. return 형식을 함수 내에서 정의해서 output 을 뱉음 -> 나중에 response_model 쓸 수 있게 바꿀 예정.

router = APIRouter()

cpu_device = torch.device("cpu") 

# Check
# 리뷰정보 가져오는 곳 바꾸기
# 파일명 review_0510_1655.csv
engine = create_engine(LocalConfig.DB_URL)

query_review = 'SELECT * FROM reviews'
DF = pd.read_sql_query(sql=text(query_review), con=engine.connect())

#DF =  pd.read_csv('/Users/hwangjaesung/Documents/capstone/Back/review_0510_1655.csv')

def fetch_store_info(idxs,scores):
    
    dataframe = DF
    info = dataframe.loc[idxs,['store','reviewtext']]
    info['score']=scores
    info_df = pd.DataFrame(info)

    info_df.drop_duplicates(subset=['store'],inplace=True)

    info_df = info_df[info_df['score']>=60]

    # Check
    # 가게정보 가져오는 부분 바꾸기
    # 파일명 store_0507_1614.csv
    query_store = 'SELECT * FROM stores'
    store = pd.read_sql_query(sql=text(query_store), con=engine.connect())
    
    info_df_merge = info_df.merge(store,left_on='store',right_on='store',how='left')

    top_n = 5
    results = info_df_merge[['store','address','reviewtext','score','category']].head(top_n)
        
    return results

def search(query: str):
    model = SentenceTransformer('jhgan/ko-sroberta-multitask',device=cpu_device)
    
    if path.exists('encoded_data_0510_1925.npy') == False:
          download_from_aws('encoded_data_0510_1925.npy', 'zzup-s3-bucket', 'encoded_data_0510_1925.npy')
    encoded_data = np.load('encoded_data_0510_1925.npy') 
    
    #encoded_data = np.load('/Users/hwangjaesung/Documents/capstone/Back/encoded_data_0510_1925.npy')

    index = faiss.IndexIDMap(faiss.IndexFlatIP(768))
    index.add_with_ids(encoded_data,np.array(range(0,len(DF))))
    
    query_vector = model.encode([query])
    
    top_k = 100
    top_k = index.search(query_vector, top_k)

    top_k_sim_score = top_k[0].tolist()[0]

    top_k_ids = top_k[1].tolist()[0]
    top_k_ids = list(np.unique(top_k_ids))

    search_dict ={}
    search_dict['idxs'] = top_k_ids
    search_dict['scores'] = top_k_sim_score
    
    return search_dict
  
@router.post('/chatRRS', status_code=200) 
async def chatrrsModel(query : str):
  search_dict = search(query)
  results = fetch_store_info(**search_dict)
  final = results.to_dict(orient='records')
  return final

@router.post('/chatRRS/{store}', status_code = 201, response_model=list[ChatRRS_Detail_Item])
async def chatrrsModel_detail(store : str, db : Session = Depends(db.session)) :
  return db.query(Reviews).filter(Reviews.store == store).all()
   